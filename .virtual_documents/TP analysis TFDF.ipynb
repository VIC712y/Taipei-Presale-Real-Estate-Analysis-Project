














import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings(action="ignore")
pd.options.display.max_seq_items = 8000
pd.options.display.max_rows = 8000


from matplotlib import font_manager
import matplotlib.pyplot as plt

font_path = './font/NotoSerifCJKtc-VF.ttf'
font_manager.fontManager.addfont(font_path)
font_prop = font_manager.FontProperties(fname=font_path)
plt.rcParams['font.family'] = font_prop.get_name()
print("Loaded font name:", font_prop.get_name())





dftp = pd.read_csv('./train.csv', low_memory=False)
test = pd.read_csv('./test.csv', low_memory=False)
display(dftp.head(2),test.head(2))





numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numeric = [i for i in dftp.columns if dftp[i].dtype in numeric_dtypes]

n_cols = 3
n_rows = (len(numeric) + n_cols - 1) // n_cols  

plt.figure(figsize=(n_cols * 5, n_rows * 4))  

for idx, i in enumerate(numeric):
    plt.subplot(n_rows, n_cols, idx + 1)
    sns.scatterplot(data=dftp, x=i, y='price',hue='price')
    plt.tick_params(axis='x', labelsize=8)
    plt.tick_params(axis='y', labelsize=8)
    
plt.tight_layout()
plt.show()





test["Fl"] = pd.to_numeric(test["Fl"], errors='coerce')
test["Fl"] = test["Fl"].astype(float)
dftp["Fl"] = pd.to_numeric(dftp["Fl"], errors='coerce')
dftp["Fl"] = dftp["Fl"].astype(float)

# Corrected filter definition
filter = (dftp['price'] <= 20000) & (dftp['price'] >= 300) & (dftp['room'] < 10) & \
         (dftp['bath'] < 10) & (dftp['p_price'] < 300) & (dftp['c_price'] < 600) & \
         (dftp['tFl'] < 30) & (dftp['Fl'] < 30) & (dftp['tArea'] < 100) & (dftp["func"] == "Condo")

# Corrected t_filter definition
t_filter = (test['room'] < 10) & (test['bath'] < 10) & (test['p_price'] < 300) & \
           (test['c_price'] < 600) & (test['tFl'] < 30) & (test['Fl'] < 30) & \
           (test['tArea'] < 100) & (test["func"] == "Condo")

tp = dftp[filter]
test = test[t_filter]

tp.reset_index(drop=True, inplace=True)
test.reset_index(drop=True, inplace=True)

tp_analyze = tp[['year', 'bedroom', 'room', 'bath', 'unit', 'p_price', 'tArea', 'c_price', 'Fl', 'tFl', 'p_lot', 'dist_MRT']]
test_analyze = test[['year', 'bedroom', 'room', 'bath', 'unit', 'p_price', 'tArea', 'c_price', 'Fl', 'tFl', 'p_lot', 'dist_MRT']]





dist_replace = tp.groupby("dist")["p_price"].mean().sort_values(ascending=True)
dist_replace = dist_replace.reset_index()

# 給列重新命名
dist_replace.columns = ['區域', '平均價格']
# 創建區域對應升冪數字的 dictionary
dist_train = {name: idx + 1 for idx, name in enumerate(dist_replace['區域'])}
# 查看 DataFrame
display(dist_replace)

tp_analyze["dist"] = tp["dist"].replace(dist_train)
tp_analyze["dist"] = pd.to_numeric(tp_analyze["dist"], errors='coerce')
test_analyze["dist"] = test["dist"].replace(dist_train)
test_analyze["dist"] = pd.to_numeric(test_analyze["dist"], errors='coerce')


Material_replace = tp.groupby('Material')["p_price"].mean().sort_values(ascending=True)
Material_replace = Material_replace.reset_index()

# 給列重新命名
Material_replace.columns = ['建材', '平均價格']
# 創建區域對應升冪數字的 dictionary
Material_train = {name: idx + 1 for idx, name in enumerate(Material_replace['建材'])}
# 查看 DataFrame
display(Material_replace)

tp_analyze["Material"] = tp["Material"].replace(Material_train)
tp_analyze["Material"] = pd.to_numeric(tp_analyze["Material"], errors='coerce')
test_analyze["Material"] = test["Material"].replace(Material_train)
test_analyze["Material"] = pd.to_numeric(test_analyze["Material"], errors='coerce')





sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))
# 检查新的分布
sns.histplot(tp['price'], color="b", kde=True)  # 使用 kde=True 添加核密度估计曲线
ax.xaxis.grid(False)
ax.set(ylabel="Frequency")
ax.set(xlabel="SalePrice")
ax.set(title="SalePrice distribution")
sns.despine(trim=True, left=True)
plt.show()
#skewness and kurtosis
print("Skewness(偏度): %f" % tp['price'].skew())
print("Kurtosis(峰度): %f" % tp['price'].kurt())





import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import norm

# Create a new DataFrame to store the log-transformed prices
log_plot = tp[['price']].copy()
log_plot['log_price'] = np.log1p(log_plot['price'])  # log1p 表示 log(1 + x)，避免 log(0) 問題

# Calculate mean and standard deviation of the log-transformed prices
mean_log_price = log_plot['log_price'].mean()
std_log_price = log_plot['log_price'].std()

# Plot the distribution of log-transformed prices
sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))

# Plot the new distribution
sns.histplot(log_plot['log_price'], color="b", kde=True, stat="density", bins=30, label='Log-Price Distribution')  # 使用 kde=True 添加核密度估計曲線

# Generate normal distribution curve
xmin, xmax = ax.get_xlim()  # Get current x-axis limits
x = np.linspace(xmin, xmax, 100)
p = norm.pdf(x, mean_log_price, std_log_price)  # Generate normal PDF based on log price mean and std
ax.plot(x, p, 'r', linewidth=2, label='Normal Distribution')  # Plot normal distribution

# Customize the plot
ax.xaxis.grid(False)
ax.set(ylabel="Density", xlabel="Log(SalePrice)", title="Log(SalePrice) Distribution with Normal Curve")
sns.despine(trim=True, left=True)
plt.legend()
plt.show()

# Calculate skewness and kurtosis after log transformation
print("Skewness(偏度): %f" % log_plot['log_price'].skew())
print("Kurtosis(峰度): %f" % log_plot['log_price'].kurt())






data = pd.concat([tp['p_price'], tp['dist']], axis=1)
f, ax = plt.subplots(figsize=(16, 8))
fig = sns.boxplot(x="dist", y="p_price", data=data)
fig.axis(ymin=20, ymax=230);
plt.xticks(rotation=0);


data = pd.concat([tp['p_price'], tp['year']], axis=1)
f, ax = plt.subplots(figsize=(16, 8))
fig = sns.boxplot(x="year", y="p_price", data=data)
fig.axis(ymin=20, ymax=230);
plt.xticks(rotation=0);





corrmat = tp_analyze.corr()
f, ax = plt.subplots(figsize=(12, 9))
sns.heatmap(corrmat, vmax=0.9, cmap="Blues", square=True)





unique_dists = list(set(tp['dist']))
n_cols = 3  
n_rows = (len(unique_dists) + n_cols - 1) // n_cols  

plt.figure(figsize=(n_cols * 5, n_rows * 4))  

for idx, i in enumerate(unique_dists):
    distrix = (tp['dist'] == i)
    data = pd.concat([tp[distrix]['price'], tp['tArea'], tp['year']], axis=1)
    
    ax = plt.subplot(n_rows, n_cols, idx + 1)
    sns.scatterplot(ax=ax, data=data, x='tArea', y='price', hue='year', alpha=0.5, palette="crest")
    ax.set_xlim(0, 175)
    ax.set_ylim(0, 17500)
    ax.set_title(f'『{i}』總價面積分佈圖', fontsize=16)

plt.tight_layout()
plt.show()





import numpy as np

def split_dataset(dataset, test_ratio=0.30):
  test_indices = np.random.rand(len(dataset)) < test_ratio
  return dataset[~test_indices], dataset[test_indices]

train_ds_pd, valid_ds_pd = split_dataset(tp_analyze)
print("{} examples in training, {} examples in testing.".format(
    len(train_ds_pd), len(valid_ds_pd)))





from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
numerical_features = ['tArea', 'p_price', 'c_price', 'Fl', 'tFl','dist_MRT','dist']
tp_analyze[numerical_features] = scaler.fit_transform(tp_analyze[numerical_features])


tp_analyze.head(10)





import tensorflow as tf
import tensorflow_decision_forests as tfdf

label = 'p_price'
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)
valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)


tfdf.keras.get_all_models()





rf = tfdf.keras.RandomForestModel(
    task=tfdf.keras.Task.REGRESSION,
    num_trees=3000,
    max_depth=12,
    min_examples=4,
    random_seed=42
)

rf.compile(metrics=["mse"])






rf.fit(x=train_ds)


tfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=6)


inspector = rf.make_inspector()
inspector.evaluation()


# 假設有 10000 個樣本，每批次大小為 32
num_samples = 1000
batch_size = 320

# 計算總步數
steps_per_epoch = num_samples // batch_size

# 在評估過程中使用這個步數
evaluation = rf.evaluate(x=valid_ds, steps=steps_per_epoch, return_dict=True)

# 打印每個評估指標
for name, value in evaluation.items():
    print(f"{name}: {value:.4f}")



print(f"Available variable importances:")
for importance in inspector.variable_importances().keys():
  print("\t", importance)





inspector.variable_importances()["NUM_AS_ROOT"]


plt.figure(figsize=(12, 4))

# Mean decrease in AUC of the class 1 vs the others.
variable_importance_metric = "NUM_AS_ROOT"
variable_importances = inspector.variable_importances()[variable_importance_metric]

# Extract the feature name and importance values.
#
# `variable_importances` is a list of <feature, importance> tuples.
feature_names = [vi[0].name for vi in variable_importances]
feature_importances = [vi[1] for vi in variable_importances]
# The feature are ordered in decreasing importance value.
feature_ranks = range(len(feature_names))

bar = plt.barh(feature_ranks, feature_importances, label=[str(x) for x in feature_ranks])
plt.yticks(feature_ranks, feature_names)
plt.gca().invert_yaxis()

# TODO: Replace with "plt.bar_label()" when available.
# Label each bar with values
for importance, patch in zip(feature_importances, bar.patches):
  plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f"{importance:.4f}", va="top")

plt.xlabel(variable_importance_metric)
plt.title("NUM AS ROOT of the class 1 vs the others")
plt.tight_layout()
plt.show()


test_analyze.head(3)


test_analyze.head(10).to_csv("testexp.csv",index = False)





test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(
    test_analyze,
    task = tfdf.keras.Task.REGRESSION)
preds = rf.predict(test_ds)
prise = pd.DataFrame({'p_price': preds.squeeze()})
output = test.copy()
output['predict_price'] = prise['p_price']
output['deviation'] = (output['p_price']-output['predict_price'])/output['predict_price']
output['deviation'] = output['deviation'].apply(lambda x: "{:.2%}".format(x))

# 將 'p_price' 和 'predict_price' 四捨五入至小數點後兩位
output['predict_price'] = output['predict_price'].round(2)


output=output[['dist', 'address', 'p_name', 'tArea',
       'p_price', 'predict_price','deviation',   'p_lot', 'c_price', 'func', 'bath','Material','dist_MRT', 'station' ,'room', 'Fl', 'tFl',
       'date', 'year']] 


# 去掉百分比符號並轉換為浮點數
output['deviation'] = output['deviation'].str.rstrip('%').astype('float') / 100

# 篩選偏差平方大於等於 0.25 的行
output.head()


output_filtered = output[(output["deviation"]**2) >= 0.025]
output_filtered.head()





from sklearn.metrics import r2_score
actual_values = output['p_price'].values  # 實際值
predicted_values = output['predict_price'].values  # 預測值

# 計算 R²
r2 = r2_score(actual_values, predicted_values)

print(f"R² 值: {r2:.4f}")

